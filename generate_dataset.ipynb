{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "026315cf-9f69-4060-922a-e2c68876617a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Criando Catalogos, Schemas e Volumes Necessários para o Estudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "644217f6-ec43-49e1-b350-eb9853ff8702",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "\n",
    "CREATE CATALOG IF NOT EXISTS costumers_registrations\n",
    "COMMENT \"Catalogo de cadastros e pedidos\";\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS costumers_registrations.raw\n",
    "COMMENT \"Base de dados de clientes\";\n",
    "\n",
    "CREATE VOLUME IF NOT EXISTS costumers_registrations.raw.registrations\n",
    "COMMENT \"Volume de dados dos clientes cadastrados\";\n",
    "\n",
    "CREATE VOLUME IF NOT EXISTS costumers_registrations.raw.orders\n",
    "COMMENT \"Volume de dados dos pedidos dos clientes\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "301792dd-f100-4d8a-90d8-c30ed546fe76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Importando Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a7f5da0-93e5-4a7c-a190-58f3fcfcb071",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "from faker import Faker\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "770b48da-e8a1-4492-aada-5390fca8c6f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Inferindo os Schemas\n",
    "-----\n",
    "\n",
    "Essa abordagem torna o script mais eficiênte, devido a não necessidade de inferir os schemas automáticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8985b9b7-b7af-4c2b-ae35-91aeb3dc0de6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "schema_cadastro = StructType([\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('nome', StringType(), True),\n",
    "    StructField('data_nascimento', DateType(), True),\n",
    "    StructField('cpf', StringType(),True),\n",
    "    StructField('cep', StringType(), True),\n",
    "    StructField('cidade', StringType(), True),\n",
    "    StructField('estado', StringType(), True),\n",
    "    StructField('pais', StringType(), True),\n",
    "    StructField('genero', StringType(), True),\n",
    "    StructField('telefone', StringType(), True),\n",
    "    StructField('email', StringType(), True),\n",
    "    StructField('data_cadastro', DateType(), True)\n",
    "])\n",
    "\n",
    "schema_pedido = StructType([\n",
    "    StructField('id_pedido', StringType(), True),\n",
    "    StructField('cpf', StringType(), True),\n",
    "    StructField('valor_pedido', DoubleType(), True),\n",
    "    StructField('valor_frete', DoubleType(), True),\n",
    "    StructField('valor_desconto', DoubleType(), True),\n",
    "    StructField('cupom', StringType(), True),\n",
    "    StructField('endereco_entrega_logradouro', StringType(), True),\n",
    "    StructField('endereco_entrega_numero', IntegerType(), True),\n",
    "    StructField('endereco_entrega_bairro', StringType(), True),\n",
    "    StructField('endereco_entrega_cidade', StringType(), True),\n",
    "    StructField('endereco_entrega_estado', StringType(), True),\n",
    "    StructField('endereco_entrega_pais', StringType(), True),\n",
    "    StructField('status_pedido', StringType(), True),\n",
    "    StructField('data_pedido', DateType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d65253e0-d9e8-4a0e-a0e4-9987ca62f8b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Função de Construção da Tabela Cadastross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af439e4-0f7d-48dc-891b-b695bfb130c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Método Utilizando Apenas Python Puro + Driver\n",
    "\n",
    "Esse método é menos performático, pois o único momento em que estamos usando spark + cluster é na linha \n",
    "\n",
    "return spark.createDataFame(data, schema=schema_cadastro)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# fake = Faker('pt_BR') # Configura Faker para gerar dados em português\n",
    "\n",
    "# def gerar_dados_cadastro_driver(n_linhas:100000):\n",
    "#     # Gera dados de um \"dia\" para a tabela de cadastros utilizando o Driver + Python Puro\n",
    "\n",
    "#     data = []\n",
    "#     for _ in range(n_linhas):\n",
    "#         data.append({\n",
    "#             'id': str(uuid.uuid4()), # Gera ID único\n",
    "#             'nome': fake.name(),\n",
    "#             'data_nascimento': fake.date_of_birth(minimum_age=18, maximum_age=90),\n",
    "#             'cpf': fake.cpf(),\n",
    "#             'cep': fake.postcode(),\n",
    "#             'cidade': fake.city(),\n",
    "#             'estado': fake.state(),\n",
    "#             'pais': fake.current_country(),\n",
    "#             'genero': fake.random_element(elements=['M', 'F']),\n",
    "#             'telefone': fake.phone_number(),\n",
    "#             'email': fake.email(),\n",
    "#             'data_cadastro': fake.date_between(start_date='-2y', end_date='today')\n",
    "#         })\n",
    "#     return spark.createDataFrame(data, schema=schema_cadastro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68086419-89fb-4320-9288-0bebcb990d32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método Utilizando Spark + Cluster\n",
    "\n",
    "Esse método é mais performático, pois estamos usando spark + cluster para gerar os dados\n",
    "\"\"\"\n",
    "\n",
    "def gerar_dados_cadastro_cluster(n_linhas: int = 100000):\n",
    "    # Gera dados de um \"dia\" para a tabela de cadastros utilizando o Cluster + Spark\n",
    "\n",
    "    def gerar_particao(iterator):\n",
    "        fake = Faker('pt_BR') # Instância por executor, cria dados em português\n",
    "\n",
    "        for pdf in iterator:\n",
    "            tamanho = len(pdf)\n",
    "\n",
    "            data = {\n",
    "                'id': [str(uuid.uuid4()) for _ in range(tamanho)],\n",
    "                'nome': [fake.name() for _ in range(tamanho)],\n",
    "                'data_nascimento': [\n",
    "                    fake.date_of_birth(minimum_age=18, maximum_age=90)\n",
    "                    for _ in range(tamanho)\n",
    "                ],\n",
    "                'cpf': [fake.cpf() for _ in range(tamanho)],\n",
    "                'cep': [fake.postcode() for _ in range(tamanho)],\n",
    "                'cidade': [fake.city() for _ in range(tamanho)],\n",
    "                'estado': [fake.state() for _ in range(tamanho)],\n",
    "                'pais': [fake.current_country() for _ in range(tamanho)],\n",
    "                'genero': [\n",
    "                    fake.random_element(elements=('M', 'F'))\n",
    "                    for _ in range(tamanho)\n",
    "                    ],\n",
    "                'telefone': [fake.phone_number() for _ in range(tamanho)],\n",
    "                'email': [fake.email() for _ in range(tamanho)],\n",
    "                'data_cadastro': [\n",
    "                    fake.date_between(start_date='-2y', end_date='today')\n",
    "                    for _ in range(tamanho)\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            yield pd.DataFrame(data)\n",
    "\n",
    "    return (\n",
    "        spark\n",
    "        .range(n_linhas)\n",
    "        .mapInPandas(gerar_particao, schema=schema_cadastro)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7947f0a4-b2ff-4021-b4ca-11cf494064f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def gerar_pedidos_cluster(DataFrame_cadastros, n_pedidos: int = 500000):\n",
    "    # Gera dados de um \"dia\" para a tabela de pedidos utilizando o Cluster + Spark\n",
    "\n",
    "    cpf_cadastros = DataFrame_cadastros.select('cpf').distinct()\n",
    "\n",
    "    # Criando base distribuída de pedidos\n",
    "    pedidos_base = (\n",
    "        spark.range(n_pedidos)\n",
    "        .withColumn('rand_key', rand())\n",
    "    )\n",
    "\n",
    "    # Criando chave aleatória também nos CPFs\n",
    "    cpfs_random = cpf_cadastros.withColumn('rand_key', rand())\n",
    "\n",
    "    # Join aleatório\n",
    "    pedidos_com_cpf = (\n",
    "        pedidos_base\n",
    "        .join(cpfs_random, on='rand_key', how='left')\n",
    "        .drop('rand_key')\n",
    "    )\n",
    "\n",
    "    def gerar_particao(iterador):\n",
    "        fake = Faker('pt_BR') # Instância por executor, cria dados em português\n",
    "\n",
    "        for pdf in iterador:\n",
    "            tamanho = len(pdf)\n",
    "\n",
    "            valor_pedido = [round(random.uniform(50, 1000), 2) for _ in range(tamanho)]\n",
    "            valor_frete = [round(random.uniform(5, 100), 2) for _ in range(tamanho)]\n",
    "            valor_desconto = [\n",
    "                random.choice([0, round(random.uniform(5, 100), 2)])\n",
    "                for _ in range(tamanho)\n",
    "            ]\n",
    "\n",
    "            status_list = random.choices(\n",
    "                ['faturado', 'aguardando pagamento', 'cancelado'],\n",
    "                weights=[80, 15, 5],\n",
    "                k=tamanho\n",
    "            )\n",
    "\n",
    "            data = {\n",
    "                'id_pedido': [str(uuid.uuid4()) for _ in range(tamanho)],\n",
    "                'cpf': pdf['cpf'],\n",
    "                'valor_pedido': valor_pedido,\n",
    "                'valor_frete': valor_frete,\n",
    "                'valor_desconto': valor_desconto,\n",
    "                'cupom': [\n",
    "                    fake.word() if valor_desconto[i] > 0 else None\n",
    "                    for i in range(tamanho)\n",
    "                ],\n",
    "                'endereco_entrega_logradouro': [fake.street_name() for _ in range(tamanho)],\n",
    "                'endereco_entrega_numero': [fake.building_number() for _ in range(tamanho)],\n",
    "                'endereco_entrega_bairro': [fake.neighborhood() for _ in range(tamanho)],\n",
    "                'endereco_entrega_cidade': [fake.city() for _ in range(tamanho)],\n",
    "                'endereco_entrega_estado': [fake.state() for _ in range(tamanho)],\n",
    "                'endereco_entrega_pais': [fake.current_country() for _ in range(tamanho)],\n",
    "                'status_pedido': status_list,\n",
    "                'data_pedido': [fake.date_between(start_date='-2y', end_date='today')\n",
    "                                for _ in range(tamanho)]\n",
    "            }\n",
    "\n",
    "            yield pd.DataFrame(data)\n",
    "\n",
    "    return (\n",
    "        pedidos_com_cpf.mapInPandas(gerar_particao, schema=schema_pedido)\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95bf65c7-e867-409f-bbe4-ea112cdb56e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.fs.rm('/Volumes/dataset_cadastros/clientes/cadastros', recurse=True)\n",
    "# dbutils.fs.rm('/Volumes/dataset_cadastros/clientes/pedidos', recurse=True)\n",
    "\n",
    "df_cad = gerar_dados_cadastro_cluster(1_000_000)\n",
    "df_ped = gerar_pedidos_cluster(df_cad, 5_000_000)\n",
    "\n",
    "df_cad.write.mode(\"overwrite\").parquet(\"/Volumes/costumers_registrations/raw/registrations\")\n",
    "df_ped.write.mode(\"overwrite\").parquet(\"/Volumes/costumers_registrations/raw/orders\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "faker"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6337514490408548,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "generate_dataset",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
